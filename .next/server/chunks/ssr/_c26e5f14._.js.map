{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 7, "column": 0}, "map": {"version":3,"sources":["file:///home/runner/workspace/app/Docs/big_data/page.jsx"],"sourcesContent":["\"use client\";\nimport React from \"react\";\n\nconst BigDataEngineeringCourse = () => {\n  return (\n    <div className=\"max-w-5xl mx-auto p-8 bg-white\">\n      <article className=\"prose prose-lg max-w-none\">\n        {/* Title */}\n        <h1 className=\"text-3xl font-bold text-gray-900 mb-8 border-b-4 border-purple-500 pb-4\">\n          Big Data Engineering Full Course Part 1 (17 Hours) — YouTube\n        </h1>\n\n        {/* Overview */}\n        <h2 className=\"text-2xl font-semibold text-gray-800 mt-8 mb-4\">\n          What the Course Is\n        </h2>\n        <p className=\"text-gray-700 leading-relaxed mb-6\">\n          The{\" \"}\n          <strong>“Big Data Engineering Full Course Part 1 (17 hours)”</strong>{\" \"}\n          is presented as a <strong>comprehensive full course</strong> on{\" \"}\n          <em>big data engineering</em>, blending theory with practical\n          demonstrations. It is aimed at learners who want to{\" \"}\n          <strong>become data engineers</strong> or gain deep knowledge in{\" \"}\n          <em>big data tools, architectures, and interview preparation</em>.{\" \"}\n          This is Part 1 of the course, with at least one continuation (Part 2)\n          covering additional advanced topics.\n        </p>\n\n        {/* Course Modules */}\n        <h2 className=\"text-2xl font-semibold text-gray-800 mt-10 mb-4\">\n          Inferred / Likely Course Content & Modules\n        </h2>\n        <ul className=\"list-disc list-inside text-gray-700 space-y-3 mb-6\">\n          <li>\n            <strong>Introduction to Big Data & Data Engineering</strong> — What\n            is Big Data? Why it matters, the role of a Data Engineer, and the 5\n            V’s (Volume, Velocity, Variety, Veracity, Value).\n          </li>\n          <li>\n            <strong>Big Data Ecosystem & Tools Overview</strong> — Hadoop, HDFS,\n            YARN, MapReduce basics.\n          </li>\n          <li>\n            <strong>Distributed Storage & File Systems</strong> — HDFS\n            internals, replication, block management, and fault tolerance.\n          </li>\n          <li>\n            <strong>MapReduce & Batch Processing</strong> — Programming model,\n            map/reduce jobs, combiners, partitioners.\n          </li>\n          <li>\n            <strong>Data Warehousing / OLAP & Big Data</strong> — Data lakes vs\n            warehouses, schema design, OLAP cubes.\n          </li>\n          <li>\n            <strong>Spark & In-Memory Processing</strong> — Apache Spark,\n            RDDs/DataFrames, Spark SQL, Spark Streaming, optimizations.\n          </li>\n          <li>\n            <strong>Hive, Pig & Higher-Level Query Engines</strong> — Hive SQL,\n            architecture, Pig Latin, query execution.\n          </li>\n          <li>\n            <strong>NoSQL Databases & Data Stores</strong> — HBase, Cassandra,\n            key-value, document, and wide-column stores.\n          </li>\n          <li>\n            <strong>Data Ingestion & ETL / ELT Pipelines</strong> — Batch and\n            streaming ingestion, pipelines, workflow orchestration.\n          </li>\n          <li>\n            <strong>Streaming & Real-Time Processing</strong> — Kafka, Flink,\n            Spark Streaming, event windows, latency handling.\n          </li>\n          <li>\n            <strong>Data Modeling & Partitioning / Sharding</strong> —\n            Partition strategies, bucketing, shard design for scalability.\n          </li>\n          <li>\n            <strong>Indexing, Compression & Performance Optimizations</strong> —\n            Parquet, ORC, Avro formats, compression, indexing, query\n            optimization.\n          </li>\n          <li>\n            <strong>Cluster & Resource Management</strong> — YARN, Mesos,\n            Kubernetes integration, scheduling, and resource allocation.\n          </li>\n          <li>\n            <strong>Security, Governance & Data Quality</strong> — Kerberos,\n            ACLs, encryption, metadata management, validation/cleansing.\n          </li>\n          <li>\n            <strong>Monitoring, Logging & Debugging</strong> — Ganglia,\n            Prometheus, log analysis, alerting.\n          </li>\n          <li>\n            <strong>Scaling, Fault Tolerance & High Availability</strong> —\n            Replication, failover, recovery strategies, resilience.\n          </li>\n          <li>\n            <strong>Case Studies & Real-World Examples</strong> — End-to-end\n            workflows, industry pipelines, dataset demos.\n          </li>\n          <li>\n            <strong>Interview Preparation / Best Practices</strong> — Common\n            questions, system design for data engineering, tips.\n          </li>\n          <li>\n            <strong>Advanced Topics (likely in Part 2)</strong> — Graph\n            processing, ML on big data, advanced streaming, ML pipelines.\n          </li>\n        </ul>\n\n        {/* Course Offers */}\n        <h2 className=\"text-2xl font-semibold text-gray-800 mt-10 mb-4\">\n          What the Course Offers\n        </h2>\n        <ul className=\"list-disc list-inside text-gray-700 space-y-2 mb-6\">\n          <li>\n            A mix of <strong>theory and practical demonstrations</strong>.\n          </li>\n          <li>\n            Coverage of major big data tools:{\" \"}\n            <strong>Hadoop, Spark, Hive, HDFS, Kafka, etc.</strong>\n          </li>\n          <li>\n            <strong>Interview preparation guidance</strong> with likely\n            questions and architecture scenarios.\n          </li>\n          <li>\n            <strong>Long-form learning</strong> (~17 hours for Part 1) to go\n            deep into multiple topics.\n          </li>\n          <li>\n            A complementary <strong>Part 2</strong> to extend the syllabus with\n            advanced concepts.\n          </li>\n        </ul>\n\n        {/* Expected Outcomes */}\n        <h2 className=\"text-2xl font-semibold text-gray-800 mt-10 mb-4\">\n          Expected Outcomes\n        </h2>\n        <ul className=\"list-disc list-inside text-gray-700 space-y-2 mb-6\">\n          <li>Solid understanding of Big Data principles and tools.</li>\n          <li>\n            Hands-on knowledge of Hadoop, Spark, Hive, Kafka, and related\n            systems.\n          </li>\n          <li>\n            Ability to design and implement scalable{\" \"}\n            <strong>data pipelines and architectures</strong>.\n          </li>\n          <li>\n            Readiness for <strong>data engineering interviews</strong> with\n            practical and theoretical grounding.\n          </li>\n          <li>\n            Preparation for deeper study in Part 2 (advanced streaming, ML on\n            big data).\n          </li>\n        </ul>\n\n        {/* Final Notes */}\n        <h2 className=\"text-2xl font-semibold text-gray-800 mt-10 mb-4\">\n          Final Notes\n        </h2>\n        <p className=\"text-gray-700 leading-relaxed mb-6\">\n          The <strong>Big Data Engineering Full Course (Part 1)</strong> on{\" \"}\n          <strong>YouTube</strong> provides an{\" \"}\n          <em>in-depth foundation in big data tools and techniques</em>. With\n          nearly 17 hours of structured content, it equips learners with the{\" \"}\n          <strong>skills, tools, and interview readiness</strong> needed to\n          pursue a career in data engineering, while setting the stage for{\" \"}\n          advanced topics in Part 2.\n        </p>\n\n        {/* Meta Info */}\n        <hr className=\"my-8 border-gray-300\" />\n        <div className=\"text-sm text-gray-600 bg-gray-50 p-4 rounded-lg\">\n          <p className=\"mb-1\">\n            <strong>Instructor:</strong> YouTube Educator (Unnamed)\n          </p>\n          <p className=\"mb-1\">\n            <strong>Platform:</strong> YouTube\n          </p>\n          <p className=\"mb-1\">\n            <strong>Duration:</strong> ~17 Hours (Part 1)\n          </p>\n          <p>\n            <strong>Level:</strong> Beginner → Intermediate → Interview Ready\n          </p>\n        </div>\n      </article>\n    </div>\n  );\n};\n\nexport default BigDataEngineeringCourse;\n"],"names":[],"mappings":";;;;AACA;AADA;;;AAGA,MAAM,2BAA2B;IAC/B,qBACE,8OAAC;QAAI,WAAU;kBACb,cAAA,8OAAC;YAAQ,WAAU;;8BAEjB,8OAAC;oBAAG,WAAU;8BAA0E;;;;;;8BAKxF,8OAAC;oBAAG,WAAU;8BAAiD;;;;;;8BAG/D,8OAAC;oBAAE,WAAU;;wBAAqC;wBAC5C;sCACJ,8OAAC;sCAAO;;;;;;wBAA8D;wBAAI;sCACxD,8OAAC;sCAAO;;;;;;wBAAkC;wBAAI;sCAChE,8OAAC;sCAAG;;;;;;wBAAyB;wBACuB;sCACpD,8OAAC;sCAAO;;;;;;wBAA8B;wBAA2B;sCACjE,8OAAC;sCAAG;;;;;;wBAA6D;wBAAE;wBAAI;;;;;;;8BAMzE,8OAAC;oBAAG,WAAU;8BAAkD;;;;;;8BAGhE,8OAAC;oBAAG,WAAU;;sCACZ,8OAAC;;8CACC,8OAAC;8CAAO;;;;;;gCAAoD;;;;;;;sCAI9D,8OAAC;;8CACC,8OAAC;8CAAO;;;;;;gCAA4C;;;;;;;sCAGtD,8OAAC;;8CACC,8OAAC;8CAAO;;;;;;gCAA2C;;;;;;;sCAGrD,8OAAC;;8CACC,8OAAC;8CAAO;;;;;;gCAAqC;;;;;;;sCAG/C,8OAAC;;8CACC,8OAAC;8CAAO;;;;;;gCAA2C;;;;;;;sCAGrD,8OAAC;;8CACC,8OAAC;8CAAO;;;;;;gCAAqC;;;;;;;sCAG/C,8OAAC;;8CACC,8OAAC;8CAAO;;;;;;gCAA+C;;;;;;;sCAGzD,8OAAC;;8CACC,8OAAC;8CAAO;;;;;;gCAAsC;;;;;;;sCAGhD,8OAAC;;8CACC,8OAAC;8CAAO;;;;;;gCAA6C;;;;;;;sCAGvD,8OAAC;;8CACC,8OAAC;8CAAO;;;;;;gCAAyC;;;;;;;sCAGnD,8OAAC;;8CACC,8OAAC;8CAAO;;;;;;gCAAgD;;;;;;;sCAG1D,8OAAC;;8CACC,8OAAC;8CAAO;;;;;;gCAA0D;;;;;;;sCAIpE,8OAAC;;8CACC,8OAAC;8CAAO;;;;;;gCAAsC;;;;;;;sCAGhD,8OAAC;;8CACC,8OAAC;8CAAO;;;;;;gCAA4C;;;;;;;sCAGtD,8OAAC;;8CACC,8OAAC;8CAAO;;;;;;gCAAwC;;;;;;;sCAGlD,8OAAC;;8CACC,8OAAC;8CAAO;;;;;;gCAAqD;;;;;;;sCAG/D,8OAAC;;8CACC,8OAAC;8CAAO;;;;;;gCAA2C;;;;;;;sCAGrD,8OAAC;;8CACC,8OAAC;8CAAO;;;;;;gCAA+C;;;;;;;sCAGzD,8OAAC;;8CACC,8OAAC;8CAAO;;;;;;gCAA2C;;;;;;;;;;;;;8BAMvD,8OAAC;oBAAG,WAAU;8BAAkD;;;;;;8BAGhE,8OAAC;oBAAG,WAAU;;sCACZ,8OAAC;;gCAAG;8CACO,8OAAC;8CAAO;;;;;;gCAA4C;;;;;;;sCAE/D,8OAAC;;gCAAG;gCACgC;8CAClC,8OAAC;8CAAO;;;;;;;;;;;;sCAEV,8OAAC;;8CACC,8OAAC;8CAAO;;;;;;gCAAuC;;;;;;;sCAGjD,8OAAC;;8CACC,8OAAC;8CAAO;;;;;;gCAA2B;;;;;;;sCAGrC,8OAAC;;gCAAG;8CACc,8OAAC;8CAAO;;;;;;gCAAe;;;;;;;;;;;;;8BAM3C,8OAAC;oBAAG,WAAU;8BAAkD;;;;;;8BAGhE,8OAAC;oBAAG,WAAU;;sCACZ,8OAAC;sCAAG;;;;;;sCACJ,8OAAC;sCAAG;;;;;;sCAIJ,8OAAC;;gCAAG;gCACuC;8CACzC,8OAAC;8CAAO;;;;;;gCAAyC;;;;;;;sCAEnD,8OAAC;;gCAAG;8CACY,8OAAC;8CAAO;;;;;;gCAAoC;;;;;;;sCAG5D,8OAAC;sCAAG;;;;;;;;;;;;8BAON,8OAAC;oBAAG,WAAU;8BAAkD;;;;;;8BAGhE,8OAAC;oBAAE,WAAU;;wBAAqC;sCAC5C,8OAAC;sCAAO;;;;;;wBAAkD;wBAAI;sCAClE,8OAAC;sCAAO;;;;;;wBAAgB;wBAAa;sCACrC,8OAAC;sCAAG;;;;;;wBAAyD;wBACM;sCACnE,8OAAC;sCAAO;;;;;;wBAA+C;wBACU;wBAAI;;;;;;;8BAKvE,8OAAC;oBAAG,WAAU;;;;;;8BACd,8OAAC;oBAAI,WAAU;;sCACb,8OAAC;4BAAE,WAAU;;8CACX,8OAAC;8CAAO;;;;;;gCAAoB;;;;;;;sCAE9B,8OAAC;4BAAE,WAAU;;8CACX,8OAAC;8CAAO;;;;;;gCAAkB;;;;;;;sCAE5B,8OAAC;4BAAE,WAAU;;8CACX,8OAAC;8CAAO;;;;;;gCAAkB;;;;;;;sCAE5B,8OAAC;;8CACC,8OAAC;8CAAO;;;;;;gCAAe;;;;;;;;;;;;;;;;;;;;;;;;AAMnC;uCAEe","debugId":null}},
    {"offset": {"line": 744, "column": 0}, "map": {"version":3,"sources":["file:///home/runner/workspace/node_modules/next/src/server/route-modules/app-page/vendored/ssr/react-jsx-dev-runtime.ts"],"sourcesContent":["module.exports = require('../../module.compiled').vendored[\n  'react-ssr'\n].ReactJsxDevRuntime\n"],"names":["module","exports","require","vendored","ReactJsxDevRuntime"],"mappings":";AAAAA,OAAOC,OAAO,GAAGC,QAAQ,4HAAyBC,QAAQ,CACxD,YACD,CAACC,kBAAkB","ignoreList":[0],"debugId":null}}]
}